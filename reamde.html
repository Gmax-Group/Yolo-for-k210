<!DOCTYPE html>
<html>
<head>
<title>reamde.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* a11y-dark theme */
/* Based on the Tomorrow Night Eighties theme: https://github.com/isagalaev/highlight.js/blob/master/src/styles/tomorrow-night-eighties.css */
/* @author: ericwbailey */

/* Comment */
.hljs-comment,
.hljs-quote {
  color: #d4d0ab;
}

/* Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
  color: #ffa07a;
}

/* Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
  color: #f5ab35;
}

/* Yellow */
.hljs-attribute {
  color: #ffd700;
}

/* Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
  color: #abe338;
}

/* Blue */
.hljs-title,
.hljs-section {
  color: #00e0e0;
}

/* Purple */
.hljs-keyword,
.hljs-selector-tag {
  color: #dcc6e0;
}

.hljs {
  display: block;
  overflow-x: auto;
  background: #2b2b2b;
  color: #f8f8f2;
  padding: 0.5em;
}

.hljs-emphasis {
  font-style: italic;
}

.hljs-strong {
  font-weight: bold;
}

@media screen and (-ms-high-contrast: active) {
  .hljs-addition,
  .hljs-attribute,
  .hljs-built_in,
  .hljs-builtin-name,
  .hljs-bullet,
  .hljs-comment,
  .hljs-link,
  .hljs-literal,
  .hljs-meta,
  .hljs-number,
  .hljs-params,
  .hljs-string,
  .hljs-symbol,
  .hljs-type,
  .hljs-quote {
        color: highlight;
    }

    .hljs-keyword,
    .hljs-selector-tag {
        font-weight: bold;
    }
}

</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h2 id="%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81%E5%AE%8C%E5%85%A8%E6%9D%A5%E6%BA%90%E4%BA%8Ehttpsgithubcomzhen8838k210yoloframework%E4%B8%BA%E4%BA%86%E8%83%BD%E5%9C%A8-win-%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BD%A0%E9%9C%80%E8%A6%81%E7%AE%80%E5%8D%95%E4%BF%AE%E6%94%B9%E5%AE%83%E7%9A%84%E4%BB%A3%E7%A0%81%E6%88%91%E5%B7%B2%E7%BB%8F%E5%AE%8C%E6%88%90%E4%BF%AE%E6%94%B9%E5%8F%AF%E4%BB%A5%E5%9C%A8-win-%E4%B8%8A%E8%BF%90%E8%A1%8C"><strong>模型训练代码完全来源于<a href="https://github.com/zhen8838/K210_Yolo_framework">https://github.com/zhen8838/K210_Yolo_framework</a>，为了能在 win 上训练模型，你需要简单修改它的代码，我已经完成修改可以在 win 上运行</strong></h2>
<h3 id="%E7%89%88%E6%9D%83%E6%89%80%E6%9C%89-seasky"><strong>@版权所有-&gt;SEASKY</strong></h3>
<h3 id="license-mit-license"><strong>LICENSE:</strong> <strong>MIT License</strong></h3>
<h3 id="%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2a-href%22httpsseasky-mastergithubioseasky-master%22httpsseasky-mastergithubioseasky-mastera">个人博客：<a href="https://seasky-master.github.io/SEASKY-Master/">https://seasky-master.github.io/SEASKY-Master/</a></h3>
<h3 id="k210-yolo-v3-%E6%A1%86%E6%9E%B6">K210 YOLO V3 框架</h3>
<h2 id="%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%B8%85%E6%99%B0%E7%9A%84%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84-yolo-v3-%E6%A1%86%E6%9E%B6">这是一个清晰的、可扩展的 yolo v3 框架。</h2>
<ol>
<li>Real-time display recall and precision</li>
<li>Easy to use with other datasets</li>
<li>Support multiple model backbones and expand more</li>
<li>Support n number of output layers and m anchors</li>
<li>Support model weight pruning</li>
<li>Portable model to kendryte K210 chip</li>
</ol>
<h2 id="voc-%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%AD%E7%BB%83-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83">VOC 数据集训练 ###开发环境</h2>
<p>原作者在 ubuntu 18.04 - Python 3.7.1 中进行测试 ,
本人尝试可以在 windows 正常训练,你需要安装 requirements.txt 中的内容
优先安装 <code>tensorflow-gpu==1.15.0</code>,如果你的电脑不支持 GPU 版本，请安装 <code>tensorflow==1.15.0</code>
<img src="tensorflow.jpg">
请在 <code>tensorflow</code> 环境搭建完成后继续向下操作，tensorflow 环境搭建参见<code>百度</code></p>
<p>然后使用<code>pip install -r requirements.txt</code>安装其他工具</p>
<h2 id="%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86">准备数据集</h2>
<p>首次使用（确保你获取到了数据集）：</p>
<pre><code>wget https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar
wget https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar
wget https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar
tar xf VOCtrainval_11-May-2012.tar
tar xf VOCtrainval_06-Nov-2007.tar
tar xf VOCtest_06-Nov-2007.tar
wget https://pjreddie.com/media/files/voc_label.py
python voc_label.py
cat 2007_train.txt 2007_val.txt 2012_*.txt &gt; train.txt    Linux使用此命令
type 2007_train.txt 2007_val.txt 2012_*.txt &gt; train.txt	  windowns使用此命令
</code></pre>
<p>注意：</p>
<ul>
<li>改变路径后重新训练需从<code>python voc_label.py</code>从新开始
然后将 IMG 路径和注释合并到一个 NPY 文件</li>
<li>win 不支持 wget，因此你需要安装相关工具，或直接在浏览器中输入 wget 后面的网址，下载后复制到改目录</li>
</ul>
<h2 id="%E7%94%9F%E6%88%90-anchors">生成 anchors</h2>
<p>加载注释生成 anchors(LOW 和 HIGH 视数据集的分布而定)：</p>
<pre><code>python make_voc_list.py train.txt data/voc_img_ann.npy
make anchors DATASET=voc ANCNUM=3
</code></pre>
<p>当你成功的时候，你会看到这样以下内容：
<img src="./readme_image/Figure_1.png" width = "800"/></p>
<p>注：结果是随机的。当你有错误时，就重新运行它。</p>
<p>如果要使用自定义数据集，只需编写脚本并生成<code>data/{dataset_name}_img_ann.npy</code>，然后使用<code>make anchors DATASET=dataset_name</code>。更多选项请参见<code>python3 ./make_anchor_list.py -h</code></p>
<p>如果要更改输出层的数目，则应修改 OUTSIZE 在 Makefile</p>
<h2 id="%E4%B8%8B%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">下载预训练模型</h2>
<p>你必须下载您想要训练的模型权重，因为默认情况下会加载训练前的权重。把文件放进./data 目录。</p>
<table>
<thead>
<tr>
<th><code>MODEL</code></th>
<th><code>DEPTHMUL</code></th>
<th>Url</th>
<th>Url</th>
</tr>
</thead>
<tbody>
<tr>
<td>yolo_mobilev1</td>
<td>0.5</td>
<td><a href="https://drive.google.com/open?id=1SmuqIU1uCLRgaePve9HgCj-SvXJB7U-I">google drive</a></td>
<td><a href="https://share.weiyun.com/59nnvtW">weiyun</a></td>
</tr>
<tr>
<td>yolo_mobilev1</td>
<td>0.75</td>
<td><a href="https://drive.google.com/open?id=1BlH6va_plAEUnWBER6vij_Q_Gp8TFFaP">google drive</a></td>
<td><a href="https://share.weiyun.com/5FgNE0b">weiyun</a></td>
</tr>
<tr>
<td>yolo_mobilev1</td>
<td>1.0</td>
<td><a href="https://drive.google.com/open?id=1vIuylSVshJ47aJV3gmoYyqxQ5Rz9FAkA">google drive</a></td>
<td><a href="https://share.weiyun.com/516LqR7">weiyun</a></td>
</tr>
<tr>
<td>yolo_mobilev2</td>
<td>0.5</td>
<td><a href="https://drive.google.com/open?id=1qjpexl4dZLMtd0dX3QtoIHxXtidj993N">google drive</a></td>
<td><a href="https://share.weiyun.com/5BwaRTu">weiyun</a></td>
</tr>
<tr>
<td>yolo_mobilev2</td>
<td>0.75</td>
<td><a href="https://drive.google.com/open?id=1qSM5iQDicscSg0MYfZfiIEFGkc3Xtlt1">google drive</a></td>
<td><a href="https://share.weiyun.com/5RRMwob">weiyun</a></td>
</tr>
<tr>
<td>yolo_mobilev2</td>
<td>1.0</td>
<td><a href="https://drive.google.com/open?id=1Qms1BMVtT8DcXvBUFBTgTBtVxQc9r4BQ">google drive</a></td>
<td><a href="https://share.weiyun.com/5dUelqn">weiyun</a></td>
</tr>
<tr>
<td>tiny_yolo</td>
<td></td>
<td><a href="https://drive.google.com/open?id=1M1ZUAFJ93WzDaHOtaa8MX015HdoE85LM">google drive</a></td>
<td><a href="https://share.weiyun.com/5413QWx">weiyun</a></td>
</tr>
<tr>
<td>yolo</td>
<td></td>
<td><a href="https://drive.google.com/open?id=17eGV6DCaFQhVoxOuTUiwi7-v22DAwbXf">google drive</a></td>
<td><a href="https://share.weiyun.com/55g6zHl">weiyun</a></td>
</tr>
</tbody>
</table>
<p>注：mobilev 不是原创的，原作者有修改它适合 K210</p>
<h2 id="train">Train</h2>
<p>使用 Mobileenet 时，需要指定 DEPTHMUL 参数。你不需要布景 DEPTHMUL 使用 tiny yolo 或 yolo.</p>
<ol>
<li>
<p>Set MODEL and DEPTHMUL to start training:</p>
<pre><code>make train MODEL=yolo_mobilev1 DEPTHMUL=0.75 MAXEP=10 ILR=0.001 DATASET=voc CLSNUM=20 IAA=False BATCH=8
</code></pre>
</li>
<li>
<p>Set CKPT to continue training:</p>
<pre><code>make train MODEL=xxxx DEPTHMUL=xx MAXEP=10 ILR=0.0005 DATASET=voc CLSNUM=20 IAA=False BATCH=16 CKPT=log/xxxxxxxxx/yolo_model.h5
</code></pre>
</li>
<li>
<p>Set IAA to enable data augment:</p>
<pre><code>make train MODEL=xxxx DEPTHMUL=xx MAXEP=10 ILR=0.0001 DATASET=voc CLSNUM=20 IAA=True BATCH=16 CKPT=log/xxxxxxxxx/yolo_model.h5
</code></pre>
</li>
<li>
<p>Use tensorboard:</p>
<pre><code>tensorboard --logdir log
</code></pre>
</li>
</ol>
<h2 id="inference">Inference</h2>
<pre><code>make inference MODEL=yolo_mobilev1 DEPTHMUL=0.75 CLSNUM=20 CKPT=log/xxxxxx/yolo_model.h5 IMG=data/people.jpg
</code></pre>
<p>你可以尝试我的模型：</p>
<pre><code>make inference MODEL=yolo_mobilev1 DEPTHMUL=0.75 CKPT=asset/yolo_model.h5 IMG=data/people.jpg
</code></pre>
<img src="./readme_image/people_res.jpg" width = "800"/>
	make inference MODEL=yolo_mobilev1 DEPTHMUL=0.75 CKPT=asset/yolo_model.h5 IMG=data/dog.jpg
<img src="./readme_image/dog_res.jpg" width = "800"/>
<p>注：由于 anchors 是随机生成的，如果您的结果与上面的图像不同，你只需要加载这个模型并继续训练一段时间。</p>
<p>更多选项请参见<code>python3 ./keras_inference.py -h</code></p>
<h2 id="prune-model">Prune Model</h2>
<pre><code>make train MODEL=xxxx MAXEP=1 ILR=0.0003 DATASET=voc CLSNUM=20 BATCH=16 PRUNE=True CKPT=log/xxxxxx/yolo_model.h5 END_EPOCH=1
</code></pre>
<p>训练结束时，将模型保存为 log/xxxxxx/yolo_prune_model.h5.</p>
<h2 id="freeze">Freeze</h2>
<pre><code>toco --output_file mobile_yolo.tflite --keras_model_file log/xxxxxx/yolo_model.h5
</code></pre>
<p>现在你有了 mobile_yolo.tflite</p>
<h2 id="%E8%BD%AC%E6%8D%A2-kmodel">转换 Kmodel</h2>
<p>Please refer nncase v0.1.0-RC5 example</p>
<pre><code>ncc mobile_yolo.tflite mobile_yolo.kmodel -i tflite -o k210model --dataset train_images
</code></pre>
<h2 id="%E5%B0%86-kmodel-%E9%83%A8%E7%BD%B2%E5%88%B0-k210">将 Kmodel 部署到 K210</h2>
<ul>
<li>见另一个文档</li>
</ul>
<p><strong>2020/7/5 21:04:35</strong></p>

</body>
</html>
